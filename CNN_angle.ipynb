{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BjU0qVSeFZDP"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.nn import Module\n",
        "from torch.nn import Conv2d\n",
        "from torch.nn import Linear\n",
        "from torch.nn import MaxPool2d\n",
        "from torch.nn import ReLU\n",
        "from torch.nn import LogSoftmax\n",
        "from torch import flatten\n",
        "from torchvision.datasets import ImageFolder\n",
        "from google.colab import drive\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "from sklearn.metrics import classification_report\n",
        "from torch.utils.data import random_split\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import KMNIST\n",
        "from torch.optim import Adam\n",
        "from torch import nn\n",
        "import matplotlib.pyplot as plt\n",
        "import argparse\n",
        "import time\n",
        "import pandas as pd\n",
        "from torchsummary import summary"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.functional import Tensor\n",
        "%cd /content/drive/MyDrive/552_project\n",
        "data_dir='/content/drive/MyDrive/552_project/images'\n",
        "temp_data = datasets.ImageFolder(data_dir, transform= transforms.Compose([\n",
        "    transforms.Resize((150,150)),transforms.ToTensor()\n",
        "]))\n",
        "angles= pd.read_excel('/content/drive/MyDrive/552_project/angles.xlsx')\n",
        "angle_speed_data=[]\n",
        "for i in range(len(angles[0])):\n",
        "  if i!=len(angles[0])-1:\n",
        "    angle_speed_data.append([angles[0][i]])\n",
        "  else:\n",
        "    angle_speed_data.append([angles[0][i]])\n",
        "angle_speed_data=Tensor(angle_speed_data)\n",
        "\n",
        "data=[]\n",
        "count=0\n",
        "for x,y in temp_data:\n",
        "  if count==0:\n",
        "    print(x.size())\n",
        "    count+=1\n",
        "  else:\n",
        "    break\n",
        "for i in range(len(temp_data)):\n",
        "  data.append([temp_data[i][0],angle_speed_data[i]])\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-ern8RTFchD",
        "outputId": "a6207a53-1056-4de2-86e2-d1622e3b30c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/552_project\n",
            "torch.Size([3, 150, 150])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "INIT_LR = 1e-3\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS = 10\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "train_size = int(0.7 * (len(data)-2))\n",
        "valid_size = int(0.1 * (len(data)-2))\n",
        "test_size = len(data) - train_size - valid_size-2\n",
        "train_dataset, test_dataset, valid_dataset = torch.utils.data.random_split(data[2:len(data)], [train_size, test_size, valid_size])\n",
        "trainDataLoader = DataLoader(train_dataset, shuffle=True,\n",
        "\tbatch_size=BATCH_SIZE)\n",
        "valDataLoader = DataLoader(valid_dataset, batch_size=BATCH_SIZE)\n",
        "testDataLoader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
        "# calculate steps per epoch for training and validation set\n",
        "trainSteps = len(trainDataLoader.dataset) // BATCH_SIZE\n",
        "valSteps = len(valDataLoader.dataset) // BATCH_SIZE"
      ],
      "metadata": {
        "id": "MBmtSRwALmAf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LeNet(Module):\n",
        "\tdef __init__(self, numChannels, regressors):\n",
        "\t\t# call the parent constructor\n",
        "\t\tsuper(LeNet, self).__init__()\n",
        "\t\t# initialize first set of CONV => RELU => POOL layers\n",
        "\t\tself.conv1 = Conv2d(in_channels=numChannels, out_channels=20,\n",
        "\t\t\tkernel_size=(5, 5))\n",
        "\t\tself.relu1 = ReLU()\n",
        "\t\tself.maxpool1 = MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
        "\t\t# initialize second set of CONV => RELU => POOL layers\n",
        "\t\tself.conv2 = Conv2d(in_channels=20, out_channels=50,\n",
        "\t\t\tkernel_size=(5, 5))\n",
        "\t\tself.relu2 = ReLU()\n",
        "\t\tself.maxpool2 = MaxPool2d(kernel_size=(4, 4), stride=(4, 4))\n",
        "\t\t# initialize first (and only) set of FC => RELU layers\n",
        "\t\tself.fc1 = Linear(in_features=800, out_features=500)\n",
        "\t\tself.relu3 = ReLU()\n",
        "\t\tself.fc2 = Linear(in_features=500, out_features=200)\n",
        "\t\tself.relu3 = ReLU()\n",
        "\t\t# initialize our softmax classifier\n",
        "\t\tself.fc3 = Linear(in_features=200, out_features=regressors)\n",
        "\t\t#self.logSoftmax = LogSoftmax(dim=1)\n",
        "\tdef forward(self, x):\n",
        "\t\t\t# pass the input through our first set of CONV => RELU =>\n",
        "\t\t\t# POOL layers\n",
        "\t\t\tx = self.conv1(x)\n",
        "\t\t\tx = self.relu1(x)\n",
        "\t\t\tx = self.maxpool1(x)\n",
        "\t\t\t#x = self.maxpool1(x)\n",
        "\t\t\t# pass the output from the previous layer through the second\n",
        "\t\t\t# set of CONV => RELU => POOL layers\n",
        "\t\t\tx = self.conv2(x)\n",
        "\t\t\tx = self.relu2(x)\n",
        "\t\t\t#x = self.maxpool2(x)\n",
        "\t\t\t#x = self.maxpool2(x)\n",
        "\t\t\tx = self.maxpool2(x)\n",
        "\t\t\tx = self.maxpool2(x)\n",
        "\t\t\t# flatten the output from the previous layer and pass it\n",
        "\t\t\t# through our only set of FC => RELU layers\n",
        "\t\t\tx = flatten(x, 1)\n",
        "\t\t\tx = self.fc1(x)\n",
        "\t\t\tx = self.relu3(x)\n",
        "\t\t\t# pass the output to our softmax classifier to get our output\n",
        "\t\t\t# predictions\n",
        "\t\t\tx = self.fc2(x)\n",
        "\t\t\tx = self.relu3(x)\n",
        "\t\t\tx = self.fc3(x)\n",
        "\t\t\toutput = x\n",
        "\t\t\treturn output"
      ],
      "metadata": {
        "id": "Oxd0mdV2Fx_C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gFicr9S_Fyyt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize the LeNet model\n",
        "print(\"[INFO] initializing the LeNet model...\")\n",
        "model = LeNet(\n",
        "\tnumChannels=3,\n",
        "\tregressors=1).to(device)\n",
        "summary(model,(3,150,150))\n",
        "# initialize our optimizer and loss function\n",
        "opt = Adam(model.parameters(), lr=INIT_LR, weight_decay=1e-3)\n",
        "lossFn = nn.MSELoss()\n",
        "# initialize a dictionary to store training history\n",
        "H = {\n",
        "\t\"train_loss\": [],\n",
        "\t\"val_loss\": []\n",
        "}\n",
        "# measure how long training is going to take\n",
        "print(\"[INFO] training the network...\")\n",
        "startTime = time.time()"
      ],
      "metadata": {
        "id": "jVQ2OGNAF1JF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f871a81-ad40-4f9d-866a-1a982164a5ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] initializing the LeNet model...\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 20, 146, 146]           1,520\n",
            "              ReLU-2         [-1, 20, 146, 146]               0\n",
            "         MaxPool2d-3           [-1, 20, 73, 73]               0\n",
            "            Conv2d-4           [-1, 50, 69, 69]          25,050\n",
            "              ReLU-5           [-1, 50, 69, 69]               0\n",
            "         MaxPool2d-6           [-1, 50, 17, 17]               0\n",
            "         MaxPool2d-7             [-1, 50, 4, 4]               0\n",
            "            Linear-8                  [-1, 500]         400,500\n",
            "              ReLU-9                  [-1, 500]               0\n",
            "           Linear-10                  [-1, 200]         100,200\n",
            "             ReLU-11                  [-1, 200]               0\n",
            "           Linear-12                    [-1, 1]             201\n",
            "================================================================\n",
            "Total params: 527,471\n",
            "Trainable params: 527,471\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.26\n",
            "Forward/backward pass size (MB): 11.08\n",
            "Params size (MB): 2.01\n",
            "Estimated Total Size (MB): 13.35\n",
            "----------------------------------------------------------------\n",
            "[INFO] training the network...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "train"
      ],
      "metadata": {
        "id": "CWyTR5GU7QGT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred_two_frame = []\n",
        "H = {\n",
        "\t\t\"train_loss\": [],\n",
        "\t\t\"val_loss\": []\n",
        "\t}\n",
        "test_loss=[0 for i in range(5)]\n",
        "for run in range(5):\n",
        "\t# initialize the LeNet model\n",
        "\tprint(\"[INFO] initializing the LeNet model...\")\n",
        "\tmodel = LeNet(\n",
        "\t\tnumChannels=3,\n",
        "\t\tregressors=1).to(device)\n",
        "\t# initialize our optimizer and loss function\n",
        "\topt = Adam(model.parameters(), lr=INIT_LR, weight_decay=1e-2)\n",
        "\tlossFn = nn.MSELoss()\n",
        "\t# initialize a dictionary to store training history\n",
        "\t\n",
        "\t# measure how long training is going to take\n",
        "\tprint(\"[INFO] training the network...\")\n",
        "\tstartTime = time.time()\t\n",
        " \n",
        "\t# loop over our epochs\n",
        "\tfor e in range(0, EPOCHS):\n",
        "\t\t# set the model in training mode\n",
        "\t\tmodel.train()\n",
        "\t\t# initialize the total training and validation loss\n",
        "\t\ttotalTrainLoss = 0\n",
        "\t\ttotalValLoss = 0\n",
        "\t\t# loop over the training set\n",
        "\t\tfor (x, y) in trainDataLoader:\n",
        "\t\t\t# send the input to the device\n",
        "\t\t\t#(x, y) = (x.to(device), y.to(device))\n",
        "\t\t\t# perform a forward pass and calculate the training loss\n",
        "\t\t\tpred = model(x)\n",
        "\t\t\tloss = lossFn(pred, y)\n",
        "\t\t\t# zero out the gradients, perform the backpropagation step,\n",
        "\t\t\t# and update the weights\n",
        "\t\t\topt.zero_grad()\n",
        "\t\t\tloss.backward()\n",
        "\t\t\topt.step()\n",
        "\t\t\t# add the loss to the total training loss so far and\n",
        "\t\t\t# calculate the number of correct predictions\n",
        "\t\t\ttotalTrainLoss += loss\n",
        "\n",
        "\t\t# switch off autograd for evaluation\n",
        "\t\twith torch.no_grad():\n",
        "\t\t\t# set the model in evaluation mode\n",
        "\t\t\tmodel.eval()\n",
        "\t\t\t# loop over the validation set\n",
        "\t\t\tfor (x, y) in valDataLoader:\n",
        "\t\t\t\tpred=model(x)\n",
        "\t\t\t\t\t\t\t# send the input to the device\n",
        "\t\t\t\t\t\t\t#(x, y) = (x.to(device), y.to(device))\n",
        "\t\t\t\t\t\t\t# make the predictions and calculate the validation loss\n",
        "\t\t\t\t#print(pred2)\n",
        "\t\t\t\ttotalValLoss += lossFn(pred, y)\n",
        "\n",
        "\t\t# calculate the average training and validation loss\n",
        "\t\tavgTrainLoss = totalTrainLoss / trainSteps\n",
        "\t\tavgValLoss = totalValLoss / valSteps\n",
        "\t\t# update our training history\n",
        "\t\tif len(H[\"train_loss\"])!=EPOCHS:\n",
        "\t\t\tH[\"train_loss\"].append([avgTrainLoss.cpu().detach().numpy()])\n",
        "\t\t\tH[\"val_loss\"].append([avgValLoss.cpu().detach().numpy()])\n",
        "\t\telse:\n",
        "\t\t\tH[\"train_loss\"][e].append(avgTrainLoss.cpu().detach().numpy())\n",
        "\t\t\tH[\"val_loss\"][e].append(avgValLoss.cpu().detach().numpy())\n",
        "\t\t# print the model training and validation information\n",
        "\t\tprint(\"[INFO] EPOCH: {}/{}\".format(e + 1, EPOCHS))\n",
        "\t\tprint(\"Train loss: {:.6f}\".format(\n",
        "\t\t\tavgTrainLoss))\n",
        "\t\tprint(\"Val loss: {:.6f}\\n\".format(\n",
        "\t\t\tavgValLoss))\n",
        "\t\n",
        "\t# finish measuring how long training took\n",
        "\tendTime = time.time()\n",
        "\tprint(\"[INFO] total time taken to train the model: {:.2f}s\".format(\n",
        "\t\tendTime - startTime))\n",
        "\t# we can now evaluate the network on the test set\n",
        "\tprint(\"[INFO] evaluating network...\")\n",
        "\t# turn off autograd for testing evaluation\n",
        "\twith torch.no_grad():\n",
        "\t\t# set the model in evaluation mode\n",
        "\t\tmodel.eval()\n",
        "\t\t\n",
        "\t\t# initialize a list to store our predictions\n",
        "\t\tpreds = []\n",
        "\t\t# loop over the test set\n",
        "\t\ttotalTestLoss=0\n",
        "\t\tfor (x, y) in testDataLoader:\n",
        "\t\t\t# send the input to the device\n",
        "\t\t\t#x = x.to(device)\n",
        "\t\t\t# make the predictions and add them to the list\n",
        "\t\t\tpred = model(x)\n",
        "\t\t\tpreds.extend(pred)\n",
        "\t\t\ttotalTestLoss += lossFn(pred, y)\n",
        "\t\t\n",
        "\t\ttotalTestLoss=totalTestLoss/len(testDataLoader)\n",
        "\t\ttest_loss[run]=totalTestLoss\n",
        "\t \n",
        "\ttwo_frames=DataLoader(data[0:2], batch_size=BATCH_SIZE)\n",
        "\t\n",
        "\twith torch.no_grad():\n",
        "\t\t# set the model in evaluation mode\n",
        "\t\tmodel.eval()\n",
        "\t\t\n",
        "\t\t# initialize a list to store our predictions\n",
        "\t\t\n",
        "\t\t# loop over the test set\n",
        "\t\tfor (x,y) in two_frames:\n",
        "\t\t\t# send the input to the device\n",
        "\t\t\t#x = x.to(device)\n",
        "\t\t\t# make the predictions and add them to the list\n",
        "\t\t\tpred = model(x)\n",
        "\t\t\tpred_two_frame.extend(pred)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 763
        },
        "id": "4di6kPO27RPC",
        "outputId": "2fea4b22-6adb-43e9-fd58-26aa3bb83673"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] initializing the LeNet model...\n",
            "[INFO] training the network...\n",
            "[INFO] EPOCH: 1/10\n",
            "Train loss: 81.476158\n",
            "Val loss: 23.897768\n",
            "\n",
            "[INFO] EPOCH: 2/10\n",
            "Train loss: 12.078143\n",
            "Val loss: 8.562062\n",
            "\n",
            "[INFO] EPOCH: 3/10\n",
            "Train loss: 4.186452\n",
            "Val loss: 4.701310\n",
            "\n",
            "[INFO] EPOCH: 4/10\n",
            "Train loss: 2.229244\n",
            "Val loss: 1.039547\n",
            "\n",
            "[INFO] EPOCH: 5/10\n",
            "Train loss: 0.687693\n",
            "Val loss: 0.558098\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-db57687ac26a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m                         \u001b[0;31m#(x, y) = (x.to(device), y.to(device))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                         \u001b[0;31m# perform a forward pass and calculate the training loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m                         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m                         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlossFn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                         \u001b[0;31m# zero out the gradients, perform the backpropagation step,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-f4fa3202ee55>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     30\u001b[0m                         \u001b[0;31m# pass the output from the previous layer through the second\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                         \u001b[0;31m# set of CONV => RELU => POOL layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m                         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m                         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                         \u001b[0;31m#x = self.maxpool2(x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    441\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    442\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 443\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred1=0\n",
        "pred2=0\n",
        "for i,pred in enumerate(pred_two_frame):\n",
        "  if i%2==0:\n",
        "    pred1+=pred\n",
        "  else:\n",
        "    pred2+=pred\n",
        "pred1=pred1/5\n",
        "pred2=pred2/5\n",
        "print(pred1,pred2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ka97h35vdF3",
        "outputId": "54e1ff4f-16fc-451b-8515-5e5a6b59d45f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.8102]) tensor([1.5646])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss=[0 for i in range(EPOCHS)]\n",
        "std_train=[0 for i in range(EPOCHS)]\n",
        "for epoch in range(EPOCHS):\n",
        "  for run in range(5):\n",
        "    train_loss[epoch]+=H[\"train_loss\"][epoch][run]\n",
        "  train_loss[epoch]=train_loss[epoch]/5\n",
        "for epoch in range(EPOCHS):\n",
        "  for run in range(5):\n",
        "    std_train[epoch]+=(H[\"train_loss\"][epoch][run]-train_loss[epoch])**2\n",
        "  std_train[epoch]=std_train[epoch]/5\n",
        "\n",
        "valid_loss=[0 for i in range(EPOCHS)]\n",
        "std_valid=[0 for i in range(EPOCHS)]\n",
        "for epoch in range(EPOCHS):\n",
        "  for run in range(5):\n",
        "    valid_loss[epoch]+=H[\"val_loss\"][epoch][run]\n",
        "  valid_loss[epoch]=valid_loss[epoch]/5\n",
        "for epoch in range(EPOCHS):\n",
        "  for run in range(5):\n",
        "    std_valid[epoch]+=(H[\"val_loss\"][epoch][run]-valid_loss[epoch])**2\n",
        "  std_valid[epoch]=std_valid[epoch]/5\n",
        "\n"
      ],
      "metadata": {
        "id": "ephGr-lSwPo1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the training loss and accuracy\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "#plt.plot(H[\"train_loss\"], label=\"train_loss\")\n",
        "plt.plot(train_loss, label=\"train_loss\")\n",
        "#plt.plot(H[\"val_loss\"], label=\"val_loss\")\n",
        "plt.plot(valid_loss, label=\"val_loss\")\n",
        "plt.title(\"Training Loss and Accuracy on Dataset\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.legend(loc=\"lower left\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "SCHC8xEf7b8N",
        "outputId": "d75059f7-e139-4404-82eb-0096ff96fe41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mean_test_loss=0\n",
        "for i in range(len(test_loss)):\n",
        "  mean_test_loss+=test_loss[i]\n",
        "mean_test_loss=mean_test_loss/len(test_loss)\n",
        "\n",
        "std_test_loss=0\n",
        "for i in range(len(test_loss)):\n",
        "  std_test_loss+=(test_loss[i]-mean_test_loss)**2\n",
        "std_test_loss=std_test_loss/len(test_loss)\n",
        "\n",
        "print('test loss=',mean_test_loss.tolist(),'+-',std_test_loss.tolist())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ex21Jz10DWmp",
        "outputId": "811c3853-cf05-4df5-be1b-c75478d59e15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test loss={0:.4f} 0.1277872771024704 +- 0.0008195413975045085\n"
          ]
        }
      ]
    }
  ]
}